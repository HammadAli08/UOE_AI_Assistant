<p align="center">
  <img src="frontend/public/unnamed.jpg" alt="UOE AI Assistant" width="120" />
</p>

<h1 align="center">UOE AI Assistant</h1>

<p align="center">
  <strong>AI-Powered Academic Assistant for the University of Education, Lahore</strong>
</p>

<p align="center">
  <img src="https://img.shields.io/badge/Python-3.12+-blue?logo=python&logoColor=white" />
  <img src="https://img.shields.io/badge/React-18.3-61DAFB?logo=react&logoColor=white" />
  <img src="https://img.shields.io/badge/FastAPI-0.110+-009688?logo=fastapi&logoColor=white" />
  <img src="https://img.shields.io/badge/OpenAI-GPT--4o--mini-412991?logo=openai&logoColor=white" />
  <img src="https://img.shields.io/badge/Pinecone-Vector_DB-00B388?logo=pinecone&logoColor=white" />
  <img src="https://img.shields.io/badge/LangSmith-Tracing-FF6F00" />
</p>

---

## ğŸ“Œ Overview

**UOE AI Assistant** is a production-grade Retrieval-Augmented Generation (RAG) chatbot that helps students of the University of Education, Lahore navigate academic programs, admissions, fee structures, and university regulations.

Students ask questions in **English or Roman Urdu**, and the system retrieves accurate, cited answers grounded in **official university documents** â€” no hallucinations, no guesswork.

### Key Highlights

- ğŸ§  **Self-Correcting Smart RAG** â€” grades every retrieved chunk, rewrites queries, and retries up to 6Ã— until relevant results are found
- ğŸ” **3 Curated Knowledge Bases** â€” BS/ADP Programs, MS/PhD Programs, Rules & Regulations
- ğŸ’¬ **Conversational Memory** â€” Redis-powered multi-turn context (10 turns, 30 min TTL)
- âš¡ **Streaming Responses** â€” real-time SSE streaming for instant user feedback
- ğŸ“Š **Full Observability** â€” LangSmith tracing on every retrieval and generation step
- ğŸ¨ **Cinematic Dark UI** â€” Framer Motion animations, responsive design, glassmorphic components

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        FRONTEND (React 18 + Vite)               â”‚
â”‚  Landing Page â†’ Chat Interface â†’ Streaming SSE â†’ State (Zustand)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚ HTTP / SSE
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     FASTAPI BACKEND (:8000)                      â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚    Query      â”‚   â”‚   Retriever  â”‚   â”‚    Generator        â”‚  â”‚
â”‚  â”‚   Enhancer    â”‚â”€â”€â–¶â”‚  (Pinecone)  â”‚â”€â”€â–¶â”‚  (GPT-4o-mini)     â”‚  â”‚
â”‚  â”‚  (GPT-4o-mini)â”‚   â”‚  3072-dim    â”‚   â”‚  Streaming SSE     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                             â”‚                                    â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”                           â”‚
â”‚                    â”‚   Smart RAG     â”‚                           â”‚
â”‚                    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚                           â”‚
â”‚                    â”‚  â”‚  Grader    â”‚ â”‚  Grade each chunk         â”‚
â”‚                    â”‚  â”‚  Rewriter  â”‚ â”‚  Rewrite if weak          â”‚
â”‚                    â”‚  â”‚  Processor â”‚ â”‚  Retry up to 6Ã—           â”‚
â”‚                    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚                           â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚    Redis      â”‚   â”‚   Pinecone   â”‚   â”‚    LangSmith        â”‚  â”‚
â”‚  â”‚   Memory      â”‚   â”‚  Vector DB   â”‚   â”‚    Tracing          â”‚  â”‚
â”‚  â”‚  (10 turns)   â”‚   â”‚  (28K+ vecs) â”‚   â”‚  @traceable         â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”¬ RAG Pipeline â€” How It Works

### Standard Flow

```
User Question â†’ Query Enhancement â†’ Vector Retrieval (Top-5) â†’ LLM Generation â†’ Streamed Answer
```

### Smart RAG Flow (Self-Correcting)

```
User Question
    â”‚
    â–¼
Query Enhancement (GPT-4o-mini rewrites for optimal retrieval)
    â”‚
    â–¼
Vector Retrieval (Pinecone, 5 docs, 3072-dim embeddings)
    â”‚
    â–¼
Chunk Grading (GPT-4o-mini scores each chunk as relevant/irrelevant)
    â”‚
    â”œâ”€â”€ âœ… â‰¥2 relevant chunks â†’ Generate answer
    â”‚
    â””â”€â”€ âŒ <2 relevant â†’ Rewrite query â†’ Re-retrieve â†’ Re-grade
                              â”‚
                              â””â”€â”€ Retry up to 6Ã— with progressive strategy
                                      â”‚
                                      â”œâ”€â”€ Found enough â†’ Generate answer
                                      â”œâ”€â”€ Some found â†’ Best-effort answer
                                      â””â”€â”€ Zero found â†’ Clarification / Fallback
```

### Pipeline Components

| Component | Model / Service | Purpose |
|-----------|----------------|---------|
| **Query Enhancer** | GPT-4o-mini | Rewrites user queries for better retrieval (handles Roman Urdu) |
| **Retriever** | Pinecone + text-embedding-3-large (3072d) | Semantic vector search across 3 namespaces |
| **Smart Grader** | GPT-4o-mini | Binary relevance grading of each retrieved chunk |
| **Smart Rewriter** | GPT-4o-mini | Progressive query rewriting when results are weak |
| **Generator** | GPT-4o-mini | Synthesizes final answer from relevant chunks via streaming |
| **Memory** | Redis Cloud | 10-turn conversational context with 30-min TTL |

---

## ğŸ“‚ Knowledge Bases

| Namespace | Documents | Vectors | Content |
|-----------|-----------|---------|---------|
| ğŸ“ `bs-adp-schemes` | BS & ADP Programs | ~20,000 | Course outlines, CLOs, prerequisites, fee structures |
| ğŸ”¬ `ms-phd-schemes` | MS & PhD Programs | ~7,300 | Postgrad eligibility, research requirements, credit hours |
| ğŸ“‹ `rules-regulations` | University Policies | ~1,600 | Attendance, grading, exam procedures, hostel rules |

**Total: ~28,800 vectors** from 141 PDF source files with 0% ingestion failure rate.

---

## ğŸ› ï¸ Tech Stack

### Backend
| Technology | Version | Purpose |
|-----------|---------|---------|
| Python | 3.12+ | Runtime |
| FastAPI | Latest | REST API + SSE streaming |
| OpenAI SDK | 1.0+ | GPT-4o-mini (chat) + text-embedding-3-large (embeddings) |
| Pinecone | 3.0+ | Vector database (3 namespaces, 3072 dimensions) |
| Redis Cloud | 5.0+ | Short-term conversational memory |
| LangSmith | 0.1+ | Tracing & observability (`@traceable` on all pipeline steps) |
| httpx | 0.27+ | HTTP/2 client |

### Frontend
| Technology | Version | Purpose |
|-----------|---------|---------|
| React | 18.3.1 | UI framework |
| Vite | 6.4+ | Build tool & dev server |
| Tailwind CSS | 3.4.15 | Utility-first styling |
| Framer Motion | 12.34+ | Scroll animations & transitions |
| Zustand | 5.0.2 | Global state management |
| React Router | 7.13+ | Client-side routing (`/` â†’ landing, `/chat` â†’ chat) |
| React Markdown | 9.0+ | Markdown rendering in chat bubbles |

### Fonts
- **Oswald** â€” Display headings (uppercase, tracking)
- **Merriweather** â€” Body text (serif, readable)
- **JetBrains Mono** â€” Code blocks

---

## ğŸ“ Project Structure

```
UOE_AI_ASSISTANT/
â”œâ”€â”€ README.md
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py                          # FastAPI app, SSE streaming endpoint
â”‚   â”œâ”€â”€ requirements.txt                 # Python dependencies
â”‚   â”œâ”€â”€ pyproject.toml                   # Project metadata
â”‚   â”‚
â”‚   â”œâ”€â”€ rag_pipeline/
â”‚   â”‚   â”œâ”€â”€ config.py                    # Central configuration (env vars, models, keys)
â”‚   â”‚   â”œâ”€â”€ pipeline.py                  # RAG orchestrator (enhance â†’ retrieve â†’ generate)
â”‚   â”‚   â”œâ”€â”€ query_enhancer.py            # GPT-4o-mini query rewriting
â”‚   â”‚   â”œâ”€â”€ retriever.py                 # Pinecone vector search + embedding cache
â”‚   â”‚   â”œâ”€â”€ generator.py                 # Streaming LLM generation
â”‚   â”‚   â”œâ”€â”€ memory.py                    # Redis conversational memory
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ smart_rag/                   # Self-correcting retrieval system
â”‚   â”‚       â”œâ”€â”€ config.py                # Smart RAG constants (6 retries, thresholds)
â”‚   â”‚       â”œâ”€â”€ grader.py                # Chunk relevance grading
â”‚   â”‚       â”œâ”€â”€ rewriter.py              # Progressive query rewriting
â”‚   â”‚       â””â”€â”€ processor.py             # Orchestrates grade â†’ rewrite â†’ retry loop
â”‚   â”‚
â”‚   â”œâ”€â”€ system_prompts/                  # Namespace-specific system prompts
â”‚   â”‚   â”œâ”€â”€ bs_adp_systemprompt.txt
â”‚   â”‚   â”œâ”€â”€ ms_phd_systemprompt.txt
â”‚   â”‚   â”œâ”€â”€ rules&regulations.txt
â”‚   â”‚   â”œâ”€â”€ query_enhancer_prompt.txt
â”‚   â”‚   â”œâ”€â”€ smart_grading_prompt.txt
â”‚   â”‚   â””â”€â”€ smart_rewrite_prompt.txt
â”‚   â”‚
â”‚   â””â”€â”€ Data_Ingestion/
â”‚       â”œâ”€â”€ pinecone_ingestion.py        # PDF â†’ chunks â†’ embeddings â†’ Pinecone
â”‚       â”œâ”€â”€ DOCUMENTATION.md             # Ingestion pipeline docs
â”‚       â””â”€â”€ processed_files.json         # Deduplication tracking
â”‚
â””â”€â”€ frontend/
    â”œâ”€â”€ index.html
    â”œâ”€â”€ package.json
    â”œâ”€â”€ vite.config.js
    â”œâ”€â”€ tailwind.config.js
    â”‚
    â”œâ”€â”€ public/                          # Static assets (logos, team photos)
    â”‚
    â””â”€â”€ src/
        â”œâ”€â”€ App.jsx                      # Root component + routing
        â”œâ”€â”€ main.jsx                     # React entry point (BrowserRouter)
        â”œâ”€â”€ constants.js                 # Namespaces, suggestions, config
        â”œâ”€â”€ index.css                    # Tailwind + custom animations
        â”‚
        â”œâ”€â”€ components/
        â”‚   â”œâ”€â”€ Landing/                 # 8-section landing page
        â”‚   â”‚   â”œâ”€â”€ HeroPage.jsx         # Page assembler
        â”‚   â”‚   â”œâ”€â”€ Navbar.jsx           # Navigation bar
        â”‚   â”‚   â”œâ”€â”€ HeroSection.jsx      # Hero with stats
        â”‚   â”‚   â”œâ”€â”€ TechMarquee.jsx      # Scrolling tech badges
        â”‚   â”‚   â”œâ”€â”€ FeaturesGrid.jsx     # Feature cards
        â”‚   â”‚   â”œâ”€â”€ HowItWorks.jsx       # 3-step process
        â”‚   â”‚   â”œâ”€â”€ KnowledgeBases.jsx   # Namespace showcase
        â”‚   â”‚   â”œâ”€â”€ TeamSection.jsx      # Team members
        â”‚   â”‚   â”œâ”€â”€ CTABanner.jsx        # Call-to-action
        â”‚   â”‚   â”œâ”€â”€ Footer.jsx           # Footer
        â”‚   â”‚   â””â”€â”€ ScrollReveal.jsx     # Scroll animation wrapper
        â”‚   â”‚
        â”‚   â”œâ”€â”€ Chat/                    # Chat interface
        â”‚   â”‚   â”œâ”€â”€ ChatContainer.jsx    # Message list + auto-scroll
        â”‚   â”‚   â”œâ”€â”€ MessageBubble.jsx    # Individual message
        â”‚   â”‚   â”œâ”€â”€ StreamingBubble.jsx  # Live streaming message
        â”‚   â”‚   â”œâ”€â”€ TypingIndicator.jsx  # Typing dots animation
        â”‚   â”‚   â””â”€â”€ WelcomeScreen.jsx    # Welcome + suggestion chips
        â”‚   â”‚
        â”‚   â”œâ”€â”€ Input/
        â”‚   â”‚   â””â”€â”€ ChatInput.jsx        # Auto-resizing input bar
        â”‚   â”‚
        â”‚   â””â”€â”€ SmartRAG/
        â”‚       â””â”€â”€ SmartBadge.jsx       # Smart RAG status badge
        â”‚
        â”œâ”€â”€ hooks/
        â”‚   â”œâ”€â”€ useChat.js               # Chat logic + SSE streaming
        â”‚   â”œâ”€â”€ useAutoResize.js         # Textarea auto-resize
        â”‚   â”œâ”€â”€ useHealthCheck.js        # Backend health polling
        â”‚   â””â”€â”€ useTheme.js              # Theme management
        â”‚
        â”œâ”€â”€ store/
        â”‚   â””â”€â”€ useChatStore.js          # Zustand store (chats, settings, namespace)
        â”‚
        â””â”€â”€ utils/
            â””â”€â”€ api.js                   # API client + SSE parser
```

---

## ğŸš€ Getting Started

### Prerequisites

- Python 3.12+
- Node.js 18+
- Redis instance (or Redis Cloud)
- Pinecone account with index
- OpenAI API key

### 1. Clone the Repository

```bash
git clone https://github.com/HammadAli08/UOE_AI_Assistant.git
cd UOE_AI_Assistant
```

### 2. Backend Setup

```bash
cd backend

# Create virtual environment
python -m venv .venv
source .venv/bin/activate   # Linux/macOS
# .venv\Scripts\activate    # Windows

# Install dependencies
pip install -r requirements.txt

# Configure environment
cp .env.example .env
# Edit .env with your actual API keys
```

**Required Environment Variables:**

```env
# API Keys
OPENAI_API_KEY=sk-...
PINECONE_API_KEY=pcsk_...
PINECONE_INDEX_NAME=uoeaiassistant

# Redis Cloud
REDIS_HOST=your-redis-host.cloud.redislabs.com
REDIS_PORT=15521
REDIS_USERNAME=default
REDIS_PASSWORD=your-redis-password

# LangSmith (optional but recommended)
LANGSMITH_TRACING=true
LANGSMITH_API_KEY=lsv2_pt_...
LANGSMITH_PROJECT=RAG_FYP
```

### 3. Start the Backend

```bash
cd backend
python main.py
# â†’ Uvicorn running on http://0.0.0.0:8000
```

### 4. Frontend Setup

```bash
cd frontend

# Install dependencies
npm install

# Start dev server
npm run dev
# â†’ Vite running on http://localhost:5173
```

### 5. Build for Production

```bash
cd frontend
npm run build
# Output â†’ frontend/dist/
```

---

## ğŸ“Š Smart RAG Configuration

| Parameter | Value | Description |
|-----------|-------|-------------|
| `max_retries` | 6 | Maximum re-retrieval attempts |
| `min_relevant_chunks` | 2 | Minimum relevant chunks to proceed |
| `confidence_threshold` | 0.6 | Minimum score for a chunk to be "relevant" |
| `early_success_threshold` | 4 | Stop retrying if this many relevant chunks found |
| `retry_top_k_boost` | 4 | Extra chunks retrieved per retry |
| `grading_model` | gpt-4o-mini | Fast + cheap chunk grading |
| `rewriting_model` | gpt-4o-mini | Progressive query rewriting |

### Smart RAG States

| State | Meaning |
|-------|---------|
| âœ… **Pass** | All chunks relevant on first retrieval |
| ğŸ”„ **Retry** | Query was rewritten to find better results |
| ğŸ”µ **Best Effort** | Used best available chunks after retries |
| ğŸ”´ **Fallback** | No relevant chunks found, general knowledge used |

---

## ğŸ”— API Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| `POST` | `/api/chat/stream` | SSE streaming chat (main endpoint) |
| `GET` | `/health` | Health check |

### Chat Request Body

```json
{
  "message": "What are the admission requirements for BS Computer Science?",
  "namespace": "bs-adp",
  "session_id": "optional-session-uuid",
  "enhance_query": true,
  "enable_smart": false,
  "top_k_retrieve": 5
}
```

### SSE Stream Events

```
data: {"type": "enhanced_query", "content": "BS Computer Science admission requirements..."}
data: {"type": "token", "content": "The"}
data: {"type": "token", "content": " admission"}
...
data: {"type": "sources", "content": [...]}
data: {"type": "smart_info", "content": {...}}
data: {"type": "done"}
```

---

## ğŸ‘¥ Team

<table>
  <tr>
    <td align="center">
      <img src="frontend/public/Hammad Ali.png" width="120" style="border-radius: 50%;" /><br />
      <strong>Hammad Ali Tahir</strong><br />
      <sub>Group Leader Â· RAG Engineer</sub>
    </td>
    <td align="center">
      <img src="frontend/public/Muhammad Muzaib.png" width="120" style="border-radius: 50%;" /><br />
      <strong>Muhammad Muzaib</strong><br />
      <sub>API Engineer</sub>
    </td>
    <td align="center">
      <img src="frontend/public/Ahmad Nawaz.png" width="120" style="border-radius: 50%;" /><br />
      <strong>Ahmad Nawaz</strong><br />
      <sub>Frontend Developer</sub>
    </td>
  </tr>
</table>

---

## ğŸ“ License

This project was developed as a **Final Year Project** at the University of Education, Lahore â€” Division of Science and Technology, Department of Information Technology.

---

<p align="center">
  Built with â¤ï¸ at the <strong>University of Education, Lahore</strong>
</p>
